{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LMSQR.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    }
  },
  "cells": [
    {
      "source": [
        "\"\"\"*****************************************************************************************\n",
        "MIT License\n",
        "Copyright (c) 2021 Jyotikrishna Dass and Rabi Mahapatra\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE.\n",
        "*****************************************************************************************\"\"\"\n",
        "\n",
        "\n",
        "\"\"\"####################################### NOTES ############################################\n",
        "# - Please cite our paper when using the code: \n",
        "#       \"Householder Sketch for Accurate and Accelerated Least-Mean-Squares Solvers\" (ICML 2021)\n",
        "#                          Jyotikrishna Dass and Rabi Mahapatra\n",
        "##########################################################################################\"\"\""
      ],
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6w9eX2QDOhwg"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn import linear_model\n",
        "from sklearn.model_selection import KFold\n",
        "import time\n",
        "import math\n",
        "import warnings\n",
        "import scipy.linalg.lapack as LAPACK\n",
        "import scipy\n",
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y46S5AI_OtGx"
      },
      "source": [
        "###################################################################################\n",
        "#             \"Fast and Accurate Least-Mean-Squares Solvers\" \n",
        "#        (NeurIPS19' - Oral presentation, Outstanding Paper Honorable Mention) \n",
        "#             Alaa Maalouf and Ibrahim Jubran and Dan Feldman\n",
        "#                    Open source code released by Authors\n",
        "#  https://github.com/ibramjub/Fast-and-Accurate-Least-Mean-Squares-Solvers/blob/master/Booster.py\n",
        "#   PAPER:   https://papers.nips.cc/paper/2019/file/475fbefa9ebfba9233364533aafd02a3-Paper.pdf\n",
        "\n",
        "#\n",
        "# We thank the authors for their open-source code and inspiring us through their work\n",
        "###################################################################################\n",
        "\n",
        "def Caratheodory(P, u, dtype='float64'):\n",
        "    \"\"\"\n",
        "    Implementation of the Caratheodory Theorem(1907)\n",
        "    input: a numpy array P containing n rows (points), each of size d, and a positive vector of weights u (that sums to 1)\n",
        "    output:a new vector of weights new_u that satisfies :\n",
        "                1. new_u is positive and sums to 1\n",
        "                2. new_u has at most d+1 non zero entries\n",
        "                3. the weighted sum of P and u (input) is the same as the weighted sum of P and new_u (output)\n",
        "    computation time: O(n^2d^2)\n",
        "    \"\"\"\n",
        "    while 1:\n",
        "        n = np.count_nonzero(u)\n",
        "        d = P.shape[1]\n",
        "        u_non_zero = np.nonzero(u)\n",
        "\n",
        "        if n <= d + 1:\n",
        "            return u\n",
        "\n",
        "        A = P[u_non_zero]\n",
        "        reduced_vec = np.outer(A[0], np.ones(A.shape[0]-1, dtype = dtype))\n",
        "        A = A[1:].T - reduced_vec\n",
        "\n",
        "        _, _, V = np.linalg.svd(A, full_matrices=True)\n",
        "        v=V[-1]\n",
        "        v = np.insert(v, [0],   -1 * np.sum(v))\n",
        "\n",
        "        idx_good_alpha = np.nonzero(v > 0)\n",
        "        alpha = np.min(u[u_non_zero][idx_good_alpha]/v[idx_good_alpha])\n",
        "\n",
        "        w = np.zeros(u.shape[0] , dtype = dtype)\n",
        "        tmp_w = u[u_non_zero] - alpha * v\n",
        "        tmp_w[np.argmin(tmp_w)] = 0.0\n",
        "        w[u_non_zero] = tmp_w\n",
        "        w[u_non_zero][np.argmin(w[u_non_zero] )] = 0\n",
        "        u = w\n",
        "\n",
        "def Fast_Caratheodory(P,u,coreset_size, dtype = 'float64'):\n",
        "    \"\"\"\n",
        "    Our fast and accurate implementation of Caratheodory's Theorem\n",
        "    Input: a numpy array P containing n rows (points), each of size d, and a positive vector of weights u (if u does not\n",
        "    sum to 1, we first normalize u by its sum, then multiply u back by its original sum before returning it)\n",
        "    Output: a new vector of positive weights new_u that satisfies :\n",
        "                 1. new_u has at most d+1 non zero entries\n",
        "                 2. the weighted sum of P and u (input) is the same as the weighted sum of P and new_u (output)\n",
        "    Computation time: O(nd+logn*d^4)\n",
        "    \"\"\"\n",
        "    d = P.shape[1]\n",
        "    n = P.shape[0]\n",
        "    m = 2*d + 2\n",
        "    if n <= d + 1:\n",
        "        return u.reshape(-1)\n",
        "\n",
        "    u_sum = np.sum(u)\n",
        "    u = u/u_sum\n",
        "    chunk_size = math.ceil(n/m)\n",
        "    current_m = math.ceil(n/chunk_size)\n",
        "\n",
        "    add_z = chunk_size - int (n%chunk_size)\n",
        "    u = u.reshape(-1,1)\n",
        "    if add_z != chunk_size:\n",
        "        zeros = np.zeros((add_z, P.shape[1]), dtype = dtype)\n",
        "        P = np.concatenate((P, zeros))\n",
        "        zeros = np.zeros((add_z, u.shape[1]), dtype = dtype)\n",
        "        u = np.concatenate((u, zeros))\n",
        "    \n",
        "    idxarray = np.array(range(P.shape[0]) )\n",
        "    \n",
        "    p_groups = P.reshape(current_m, chunk_size, P.shape[1])\n",
        "    u_groups = u.reshape(current_m, chunk_size)\n",
        "    idx_group = idxarray.reshape(current_m, chunk_size)\n",
        "    u_nonzero = np.count_nonzero(u)\n",
        "\n",
        "    if not coreset_size:\n",
        "        coreset_size = d+1\n",
        "    while u_nonzero > coreset_size:\n",
        "\n",
        "        groups_means = np.einsum('ijk,ij->ik',p_groups, u_groups)\n",
        "        group_weigts = np.ones(groups_means.shape[0], dtype = dtype)*1/current_m\n",
        "\n",
        "        Cara_u_idx = Caratheodory(groups_means , group_weigts,dtype = dtype )\n",
        "\n",
        "        IDX = np.nonzero(Cara_u_idx)\n",
        "\n",
        "        new_P = p_groups[IDX].reshape(-1,d)\n",
        "\n",
        "        subset_u = (current_m * u_groups[IDX] * Cara_u_idx[IDX][:, np.newaxis]).reshape(-1, 1)\n",
        "        new_idx_array = idx_group[IDX].reshape(-1,1)\n",
        "        ##############################################################################\n",
        "        u_nonzero = np.count_nonzero(subset_u)\n",
        "        chunk_size = math.ceil(new_P.shape[0]/ m)\n",
        "        current_m = math.ceil(new_P.shape[0]/ chunk_size)\n",
        "\n",
        "        add_z = chunk_size - int(new_P.shape[0] % chunk_size)\n",
        "        if add_z != chunk_size:\n",
        "            new_P = np.concatenate((new_P, np.zeros((add_z, new_P.shape[1]), dtype = dtype)))\n",
        "            subset_u = np.concatenate((subset_u, np.zeros((add_z, subset_u.shape[1]),dtype = dtype)))\n",
        "            new_idx_array = np.concatenate((new_idx_array, np.zeros((add_z, new_idx_array.shape[1]),dtype = dtype)))\n",
        "        p_groups = new_P.reshape(current_m, chunk_size, new_P.shape[1])\n",
        "        u_groups = subset_u.reshape(current_m, chunk_size)\n",
        "        idx_group = new_idx_array.reshape(current_m , chunk_size)\n",
        "        ###########################################################\n",
        "\n",
        "    new_u = np.zeros(n)\n",
        "    subset_u = subset_u[(new_idx_array < n)]\n",
        "    new_idx_array = new_idx_array[(new_idx_array < n)].reshape(-1).astype(int)\n",
        "    new_u[new_idx_array] = subset_u\n",
        "    return u_sum * new_u\n",
        "\n",
        "\n",
        "def linregcoreset(P, u, b=None, c_size=None, dtype='float64'):\n",
        "    \"\"\"\n",
        "    This function computes a coreset for linear regression.\n",
        "    Input: a numpy array P containing n rows (points), each of size d, a positive vector of weights u of size n, a labels\n",
        "           vector b of size n, coreset size c_size (not required).\n",
        "    Output: a new numpy array new_P containing the coreset points in its rows and a new vector new_u of positive weights,\n",
        "            and a new vector of labels new_b for the coreset. The output satisfies for every vector x that:\n",
        "                 ||sqrt(u.transpose())*(Px-b)||^2 = ||sqrt(new_u.transpose())*(new_Px-new_b)||^2\n",
        "                 i.e., the output of a call to linearRegression with the original input or with the coreset is the same.\n",
        "    Computation time: O(nd^2+logn*d^8)\n",
        "    \"\"\"\n",
        "    if b is not None:\n",
        "        P_tag = np.append(P, b, axis=1)\n",
        "    else:\n",
        "        P_tag = P\n",
        "\n",
        "    n_tag = P_tag.shape[0]; d_tag = P_tag.shape[1]\n",
        "    P_tag = P_tag.reshape(n_tag, d_tag, 1)\n",
        "    \n",
        "    P_tag = np.einsum(\"ikj,ijk->ijk\",P_tag ,P_tag)\n",
        "    P_tag = P_tag.reshape(n_tag, -1)\n",
        "    n_tag = P_tag.shape[0]; d_tag = P_tag.shape[1]\n",
        "\n",
        "    coreset_weigts = Fast_Caratheodory(P_tag.reshape(n_tag,-1), u, c_size,  dtype=dtype)\n",
        "    new_idx_array = np.nonzero(coreset_weigts)\n",
        "    coreset_weigts = coreset_weigts[new_idx_array]\n",
        "\n",
        "    if b is not None:\n",
        "        return P[new_idx_array], coreset_weigts.reshape(-1), b[new_idx_array]\n",
        "    else:\n",
        "        return P[new_idx_array], coreset_weigts.reshape(-1)\n",
        "\n",
        "\n",
        "def stream_coreset(P, u, b, folds=None, dtype='float64'):\n",
        "    \"\"\"\n",
        "    This function computes a coreset for LMS solvers that use k-fold cross validation. It partitions the data into \"folds\"\n",
        "    parts, and computes a coreset for every part using the function linregcoreset.\n",
        "    Input: a numpy array P containing n rows (points), each of size d, a positive vector of weights u of size n, a labels\n",
        "           vector b of size n, and the number of folds used in the cross validation.\n",
        "    Output: a new numpy array new_P containing the coreset points in its rows and a new vector new_u of positive weights,\n",
        "            and a new vector of labels new_b for the coreset. The output satisfies for every vector x that:\n",
        "                 ||sqrt(u.transpose())*(Px-b)||^2 = ||sqrt(new_u.transpose())*(new_Px-new_b)||^2\n",
        "                 i.e., the output of a call to linearRegression with the original input or with the coreset is the same.\n",
        "    Computation time: O(nd^2+logn*d^8)\n",
        "    \"\"\"\n",
        "    if folds is None:\n",
        "        return linregcoreset(P, u, b, dtype=dtype)\n",
        "    m = int(P.shape[0] / folds)\n",
        "\n",
        "    d = P.shape[1]\n",
        "    size_of_coreset = ((d+1)*(d+1)+1)\n",
        "\n",
        "    batches = folds\n",
        "    cc, uc, bc = linregcoreset(P[0:m], u[0:m], b[0:m], dtype=dtype)\n",
        "\n",
        "    if cc.shape[0] < size_of_coreset and folds:\n",
        "            add_z = size_of_coreset - cc.shape[0]\n",
        "            zeros = np.zeros((add_z, cc.shape[1]), dtype=dtype)\n",
        "            cc = np.concatenate((cc, zeros))\n",
        "            zeros = np.zeros((add_z), dtype=dtype)\n",
        "            uc = np.concatenate((uc, zeros))\n",
        "            zeros = np.zeros((add_z, bc.shape[1]), dtype=dtype)\n",
        "            bc = np.concatenate((bc, zeros))\n",
        "\n",
        "    for batch in range(1, batches):\n",
        "        coreset, new_u, new_b = linregcoreset(P[batch*m:(batch+1)*m], u[batch*m:(batch+1)*m], b[batch*m:(batch+1)*m], dtype=dtype)\n",
        "\n",
        "        if coreset.shape[0] < size_of_coreset and folds:\n",
        "            add_z = size_of_coreset - coreset.shape[0]\n",
        "            zeros = np.zeros((add_z, coreset.shape[1]), dtype=dtype)\n",
        "            coreset = np.concatenate((coreset, zeros))\n",
        "            zeros = np.zeros((add_z),dtype=dtype)\n",
        "            new_u = np.concatenate((new_u, zeros))\n",
        "            zeros = np.zeros((add_z, new_b.shape[1]), dtype=dtype)\n",
        "            new_b = np.concatenate((new_b, zeros))\n",
        "        bc = np.concatenate((bc, new_b))\n",
        "        cc = np.concatenate((cc, coreset))\n",
        "        uc = np.concatenate((uc, new_u))\n",
        "    return cc, uc, bc\n",
        "\n",
        "\n",
        "def test_model_(test_data, test_labels, test_weights, clf):\n",
        "    weighted_test_data = test_data * np.sqrt(test_weights[:, np.newaxis])\n",
        "    weighted_test_labels = test_labels * np.sqrt(test_weights[:, np.newaxis])\n",
        "    score = clf.score(weighted_test_data, weighted_test_labels)\n",
        "    return score\n",
        "\n",
        "\n",
        "def train_model_(data, labels, weights, clf):\n",
        "    time_start = time.time()\n",
        "    weighted_data = data * np.sqrt(weights[:, np.newaxis])\n",
        "    weighted_labels = (labels * np.sqrt(weights[:, np.newaxis])).ravel()\n",
        "    clf.fit(weighted_data, weighted_labels)\n",
        "    time_end = time.time()\n",
        "\n",
        "    return time_end - time_start, clf\n",
        "\n",
        "\n",
        "def coreset_train_model(data, labels, weights, clf, folds=None, solver='ridge'):\n",
        "    time_start = time.time()\n",
        "\n",
        "    coreset, coreset_weights, coreset_labels = stream_coreset(data, weights, labels, folds=folds)\n",
        "    weighted_coreset = coreset * np.sqrt(coreset_weights[:, np.newaxis])\n",
        "    weighted_coreset_labels = (coreset_labels * np.sqrt(coreset_weights[:, np.newaxis])).ravel()\n",
        "\n",
        "    if solver in ['lasso', 'elastic']:\n",
        "        const = np.sqrt(coreset.shape[0] / data.shape[0])\n",
        "        clf.fit(const * weighted_coreset, const * weighted_coreset_labels)\n",
        "    else:\n",
        "        clf.fit(weighted_coreset, weighted_coreset_labels)\n",
        "    time_end = time.time()\n",
        "\n",
        "    return time_end - time_start, clf\n",
        "\n",
        "###################################################################################"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6Gds-CqQlQp"
      },
      "source": [
        "###################################################################################\n",
        "#       \"Householder Sketch for Accurate and Accelerated Least-Mean-Squares Solvers\"\n",
        "#                   Jyotikrishna Dass and Rabi Mahapatra (ICML 2021)      \n",
        "#                               (Sequential LMS-QR)\n",
        "###################################################################################\n",
        "\n",
        "def train_model(data, labels, clf):\n",
        "  time_start = time.time()\n",
        "  clf.fit(data,labels.ravel())\n",
        "  time_end = time.time()\n",
        "  return time_end - time_start, clf\n",
        "\n",
        "def test_model(test_data, test_labels,clf):\n",
        "  score = clf.score(test_data, test_labels.ravel())\n",
        "  return score\n",
        "\n",
        "def qrHouseholder(X):  # LAPACK.dgeqrf\n",
        "  time_start = time.time()\n",
        "  output = LAPACK.dgeqrf(X)\n",
        "  H = output[0]\n",
        "  tau = output[1]\n",
        "  R = np.triu(H[:X.shape[1], :])\n",
        "  time_end = time.time()\n",
        "  return time_end - time_start,H, tau, R\n",
        "\n",
        "def multiplyQx(H, tau, x, side='L', trans='N'):\n",
        "  # http://www.netlib.org/lapack/explore-html/da/dba/group__double_o_t_h_e_rcomputational_ga17b0765a8a0e6547bcf933979b38f0b0.html\n",
        "  # https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.lapack.dormqr.html#scipy.linalg.lapack.dormqr\n",
        "  # side: 'L' (Q*x)  | 'R' (x*Q)    (Puts Q on left or right side of x)\n",
        "  # trans: 'N' (Q*x) | 'T' (x'*Q)   (transposes Q)\n",
        "  # tau is already defined\n",
        "  # x is also aready defined.\n",
        "  time_start = time.time()\n",
        "  output = LAPACK.dormqr(side=side, trans=trans, a=H, tau=tau, c=x, lwork=x.shape[0])\n",
        "  out_clean = np.asarray_chkfinite(output[:-2])[0]\n",
        "  time_end = time.time()\n",
        "  return time_end - time_start,out_clean\n",
        "###################################################################################"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXTNRWvjSPy7"
      },
      "source": [
        "###################################\n",
        "# LMS solvers from scikit-learn\n",
        "###################################\n",
        "\n",
        "def get_new_clf(solver, folds=3, alphas=100):\n",
        "  kf=KFold(n_splits=folds,shuffle=False)   \n",
        "  if \"linear\" == solver:\n",
        "    clf = linear_model.LinearRegression(fit_intercept=False)\n",
        "\n",
        "  if \"ridge\" == solver:\n",
        "    alphas =  np.arange(1/alphas, 10+ 1/alphas, 10/alphas)\n",
        "    clf = linear_model.RidgeCV(alphas=alphas, fit_intercept=False, cv=kf)\n",
        "\n",
        "  elif \"lasso\" == solver:\n",
        "    clf=linear_model.LassoCV(n_alphas=alphas, fit_intercept=False, cv=kf)\n",
        "\n",
        "  elif \"elastic\" == solver:\n",
        "    clf = linear_model.ElasticNetCV(n_alphas=alphas, fit_intercept=False, cv=kf)\n",
        "\n",
        "  elif \"kernelRidge\" == solver:\n",
        "    clf = KernelRidge(alpha=0.1, kernel=\"linear\")\n",
        "\n",
        "  return clf"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSWWAdNXSlt_",
        "outputId": "4f581e9c-ab11-4fe9-bb42-38ae50bd8614"
      },
      "source": [
        "###################################\n",
        "# main() \n",
        "###################################\n",
        "\n",
        "def main():\n",
        "\n",
        "  # SYNTHETIC DATASETS\n",
        "  n = 24000000\n",
        "  d = 3\n",
        "  data_range = 100\n",
        "  np.random.seed(0)\n",
        "  data = np.floor(np.random.rand(n, d) * data_range) #dtype='float32'\n",
        "  labels = np.floor(np.random.rand(n, 1) * data_range)\n",
        "  num_of_alphas = 100\n",
        "  folds = 2\n",
        "\n",
        "  # REAL DATASETS - (1)\n",
        "  # dataset = pd.read_pickle(\"3D_Spatial_network.zip\")\n",
        "  # dataset.dropna(inplace=True)\n",
        "  # data = dataset[['LONGITUDE', 'LATITUDE']].values\n",
        "  # labels = dataset[['ALTITUDE']].values\n",
        "  # n, d = data.shape\n",
        "  # num_of_alphas = 100\n",
        "  # folds = 2\n",
        "\n",
        "  # REAL DATASETS - (2)\n",
        "  # dataset = pd.read_pickle(\"household_power.zip\")\n",
        "  # dataset.dropna(inplace=True)\n",
        "  # #ns = 250000\n",
        "  # #data = dataset[['Global_active_power', 'Global_reactive_power']].iloc[:ns, :].values\n",
        "  # #labels = dataset[['Voltage']].iloc[:ns, :].values\n",
        "  # data = dataset[['Global_active_power', 'Global_reactive_power']].values\n",
        "  # labels = dataset[['Voltage']].values\n",
        "  # n, d = data.shape\n",
        "  # num_of_alphas = 100\n",
        "  # folds = 2\n",
        "\n",
        "\n",
        "  weights = np.ones(n)    \n",
        "  \n",
        "  #solverList = [\"ridge\", \"lasso\", \"elastic\", \"linear\"]\n",
        "  \n",
        "  solverList = [\"ridge\"]\n",
        "  for solver in solverList:\n",
        "\n",
        "    print(\"SOLVER: {} \\nData: {} X {} \\nnumber_of_alphas: {}\".format(solver,n,d,num_of_alphas))\n",
        "\n",
        "\n",
        "\n",
        "    print(\"\\n################ Original (no optimization) #################\")\n",
        "    \n",
        "    clf = get_new_clf(solver, folds=folds, alphas=num_of_alphas)\n",
        "    time_og, clf_og = train_model(data, labels, clf) \n",
        "    print(\"coef_original:\\n {}\\n\".format(clf_og.coef_))\n",
        "    print(\"*** RUNNING TIME ***\")\n",
        "    print (\"---->time_original = {} \\n\".format(time_og))\n",
        "    \n",
        "\n",
        "\n",
        "    print(\"\\n#################### LMSQR (Householder) ###################\")\n",
        "    \n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "    time_preprocess = 0\n",
        "    time_train = 0\n",
        "    time_hh, H, tau, R = qrHouseholder(data)  # LAPACK Householder QR for input data\n",
        "    time_Qx, qtrans_labels = multiplyQx(H, tau, labels, trans=\"T\")\n",
        "    time_preprocess = time_hh + time_Qx \n",
        "    clf = get_new_clf(solver, folds=folds, alphas=num_of_alphas)\n",
        "    time_train, clf_qr = train_model(R, qtrans_labels[0:d],clf)\n",
        "    time_LMSQR = time_preprocess + time_train\n",
        "    print(\"coef_qr:\\n {}, coef diff wrt original = {}\\n\".format(clf_qr.coef_,np.sum(np.abs(clf_og.coef_ - clf_qr.coef_)))) \n",
        "    print(\"*** RUNNING TIME ***\")\n",
        "    print(\"---->time_LMSQR (Preprocess+Train) = {}\".format(time_LMSQR))\n",
        "    print(\"    ---->time(Preprocess=A+B) = {}\".format(time_preprocess))\n",
        "    print(\"         -A-->time(Householder) = {}\".format(time_hh))\n",
        "    print(\"         -B-->time(Qx) = {}\".format(time_Qx))\n",
        "    print(\"    ---->time(Train) = {}\\n\".format(time_train))\n",
        "    print(\"*** RUNNING TIME SPEEDUP ***\")\n",
        "    print(\"LMSQR wrt original = {} X\".format(time_og/time_LMSQR))\n",
        "\n",
        "\n",
        "\n",
        "    print(\"\\n################## LMSBOOST (Caratheodory) ####################\")\n",
        "    \n",
        "    clf = get_new_clf(solver, folds=folds, alphas=num_of_alphas)\n",
        "    time_LMSBOOST, clf_caratheodory = coreset_train_model(data, labels, weights, clf, folds=folds, solver=solver)\n",
        "    print(\"coef_caratheodory:\\n {}, coef diff wrt original = {}\\n\".format(clf_caratheodory.coef_, np.sum(np.abs(clf_og.coef_ - clf_caratheodory.coef_))))\n",
        "    print(\"*** RUNNING TIME ***\")\n",
        "    print (\"---->time_LMSBOOST = {}\\n\".format(time_LMSBOOST))\n",
        "    print(\"*** RUNNING TIME SPEEDUP ***\")\n",
        "    print(\"LMSBOOST wrt original = {} X\".format(time_og/time_LMSBOOST))\n",
        "    print(\"LMSQR wrt LMSBOOST = {} X\".format(time_LMSBOOST/time_LMSQR))\n",
        "    \n",
        "    \n",
        "    if (solver == \"linear\"):\n",
        "      print(\"\\n####################### SKETCH+INVERSE #########################\")\n",
        "      time_start = time.time()\n",
        "      invX = np.linalg.inv(np.transpose(data)@data)\n",
        "      clf_sketchinv_coef_ = invX @ (np.transpose(data)@labels)\n",
        "      time_end = time.time()\n",
        "      time_SKETCHINV = time_end - time_start\n",
        "      print(\"coef_SKETCH+INVERSE:\\n {}, coef diff wrt original = {}\\n\".format(clf_sketchinv_coef_, np.sum(np.abs(clf_og.coef_ - clf_sketchinv_coef_))))\n",
        "      print(\"*** RUNNING TIME ***\")\n",
        "      print (\"---->time_SKETCH+INVERSE = {}\\n\".format(time_SKETCHINV))\n",
        "      print(\"*** RUNNING TIME SPEEDUP ***\")\n",
        "      print(\"SKETCH+INVERSE wrt original = {} X\".format(time_og/time_SKETCHINV))\n",
        "      print(\"LMSQR wrt SKETCH+INVERSE = {} X\".format(time_SKETCHINV/time_LMSQR))\n",
        "\n",
        "\n",
        "      print(\"\\n####################### SKETCH+CHOLESKY ##########################\")\n",
        "      time_start = time.time()\n",
        "      L = np.linalg.cholesky(np.transpose(data)@data)\n",
        "      invLLt = np.linalg.inv(L@np.transpose(L))\n",
        "      clf_sketchchol_coef_ = invLLt @ (np.transpose(data)@labels)\n",
        "      time_end = time.time()\n",
        "      time_SKETCHCHOLESKY = time_end - time_start\n",
        "      print(\"coef_SKETCH+CHOLESKY:\\n {}, coef diff wrt original = {}\\n\".format(clf_sketchchol_coef_, np.sum(np.abs(clf_og.coef_ - clf_sketchchol_coef_))))\n",
        "      print(\"*** RUNNING TIME ***\")\n",
        "      print (\"---->time_SKETCH+CHOLESKY= {}\\n\".format(time_SKETCHCHOLESKY))\n",
        "      print(\"*** RUNNING TIME SPEEDUP ***\")\n",
        "      print(\"SKETCH+CHOLESKY wrt original = {} X\".format(time_og/time_SKETCHCHOLESKY))\n",
        "      print(\"LMSQR wrt SKETCH+CHOLESKY = {} X\".format(time_SKETCHCHOLESKY/time_LMSQR))\n",
        " \n",
        "   \n",
        "   \n",
        "      print(\"-------------------------------------------------------------------------------------\\n\")\n",
        "\n",
        "   \n",
        "      ################ ACCURACY COMPARISON #############################\n",
        "      #######  defined in Maalouf et al (NeurIPS2019) ##################\n",
        "      ##########   for LMS = LinearRegression    #############################\n",
        "      ##################################################################\n",
        "\n",
        "      print(\"\\n*** ACCURACY COMPARISON ***\\n\")\n",
        "\n",
        "      # Original, w* = LinearRegression(X, b) and ||Xw*-b||\n",
        "      loss_og = np.linalg.norm(data@clf_og.coef_ - labels.ravel())\n",
        "      print(\"Loss original = {} \".format(loss_og))\n",
        "        \n",
        "\n",
        "      # Householder QR: w_qr =  LinearRegression(R, Q'b) and loss = ||Xw_qr-b||\n",
        "      loss_qr = np.linalg.norm(data@clf_qr.coef_ - labels.ravel())\n",
        "      print(\"Loss LMSQR = {} \". format(loss_qr))\n",
        "      #print(\"Difference in loss LMSQR = {} \". format(np.abs(loss_og-loss_qr)))\n",
        "\n",
        "\n",
        "      # Caratheodory set: w_caratheodory = LinearRegression(C, y) and loss = ||Xw_caratheodory-b||\n",
        "      loss_caratheodory = np.linalg.norm(data@clf_caratheodory.coef_ - labels.ravel())\n",
        "      print(\"Loss LMSBOOST = {} \". format(loss_caratheodory))\n",
        "      #print(\"Difference in loss LMSBOOST = {} \". format(np.abs(loss_og-loss_caratheodory)))\n",
        "\n",
        "\n",
        "      # SKETCH+INVERSE (for linear solver), w_sketchinv =  (X'X)^{-1}X'b , and ||Xw_sketchinv-b||\n",
        "      loss_sketchinv = np.linalg.norm(data@clf_sketchinv_coef_ - labels)\n",
        "      print(\"Loss SKETCH+INVERSE = {} \". format(loss_sketchinv))\n",
        "      #print(\"Difference in loss SKETCH+INVERSE = {} \". format(np.abs(loss_og-loss_sketchinv)))\n",
        "\n",
        "\n",
        "      # SKETCH+CHOLESKY (for linear solver), w_sketchchol = (LL')^{-1}A'b  and ||Xw_sketchchol-b||\n",
        "      loss_sketchchol = np.linalg.norm(data@clf_sketchchol_coef_ - labels)\n",
        "      print(\"Loss SKETCH+CHOLESKY = {} \". format(loss_sketchchol))\n",
        "      #print(\"Difference in loss SKETCH+CHOLESKY = {} \". format(np.abs(loss_og-loss_sketchchol)))\n",
        "  \n",
        "    \n",
        "      print(\"-------------------------------------------------------------------------------------\\n\")\n",
        "\n",
        "      # ############## Numerical Stability ##################\n",
        "      #######  defined in Maalouf et al (NeurIPS2019) ##################\n",
        "      ##########   for LMS = LinearRegression    #############################\n",
        "      ##################################################################\n",
        "    \n",
        "      print(\"\\n*** NUMERICAL STABILITY (lower is better) ***\\n\")\n",
        "\n",
        "      # Householder QR: w_qr =  LinearRegression(R, Q'b) and ||Xw* - Xw_qr||\n",
        "      stability_qr = np.linalg.norm((data@clf_og.coef_) - (data@clf_qr.coef_))\n",
        "      print(\"LMSQR wrt Original: {:.20}\".format(stability_qr))\n",
        "\n",
        "\n",
        "      # Caratheodory set: w_caratheodory = LinearRegression(C, y) and ||Xw* - Xw_caratheodory||\n",
        "      stability_caratheodory = np.linalg.norm((data@clf_og.coef_) - (data@clf_caratheodory.coef_))\n",
        "      print(\"LMSBOOST wrt Original: {:.20}\".format(stability_caratheodory))\n",
        "\n",
        "\n",
        "      # SKETCH+INVERSE: w_sketchinv =  (X'X)^{-1}X'b , and ||Xw* - Xw_sketchinv||\n",
        "      stability_sketchinv = np.linalg.norm((data@clf_og.coef_) - (data@clf_sketchinv_coef_))\n",
        "      print(\"SKETCH+INVERSE wrt Original: {:.20}\".format(stability_sketchinv))\n",
        "\n",
        "\n",
        "      # SKETCH+CHOLESKY, w_sketchchol = (LL')^{-1}A'b  and ||Xw* - Xw_sketchchol||\n",
        "      stability_sketchchol = np.linalg.norm((data@clf_og.coef_) - (data@clf_sketchchol_coef_))\n",
        "      print(\"SKETCH+CHOLESKY wrt Original: {:.20}\".format(stability_sketchchol))\n",
        "    \n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  main()\n",
        "  print(\"------------------------------------  END   -------------------------------------\\n\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SOLVER: ridge \n",
            "Data: 24000000 X 3 \n",
            "number_of_alphas: 100\n",
            "\n",
            "################ Original (no optimization) #################\n",
            "coef_original:\n",
            " [0.29931347 0.29917227 0.29975626]\n",
            "\n",
            "*** RUNNING TIME ***\n",
            "---->time_original = 196.09504675865173 \n",
            "\n",
            "\n",
            "#################### LMSQR (Householder) ###################\n",
            "coef_qr:\n",
            " [0.29931347 0.29917227 0.29975626], coef diff wrt original = 2.7755575615628914e-15\n",
            "\n",
            "*** RUNNING TIME ***\n",
            "---->time_LMSQR (Preprocess+Train) = 1.1159121990203857\n",
            "    ---->time(Preprocess=A+B) = 0.8937475681304932\n",
            "         -A-->time(Householder) = 0.5483131408691406\n",
            "         -B-->time(Qx) = 0.34543442726135254\n",
            "    ---->time(Train) = 0.22216463088989258\n",
            "\n",
            "*** RUNNING TIME SPEEDUP ***\n",
            "LMSQR wrt original = 175.72623270074084 X\n",
            "\n",
            "################## LMSBOOST (Caratheodory) ####################\n",
            "coef_caratheodory:\n",
            " [0.29931347 0.29917227 0.29975626], coef diff wrt original = 1.3629652961810734e-12\n",
            "\n",
            "*** RUNNING TIME ***\n",
            "---->time_LMSBOOST = 10.388382911682129\n",
            "\n",
            "*** RUNNING TIME SPEEDUP ***\n",
            "LMSBOOST wrt original = 18.87637839553791 X\n",
            "LMSQR wrt LMSBOOST = 9.309319246444003 X\n",
            "------------------------------------  END   -------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}